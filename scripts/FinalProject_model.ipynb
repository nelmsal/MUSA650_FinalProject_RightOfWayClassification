{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelmsal/MUSA650_FinalProject_RightOfWayClassification/blob/main/scripts/FinalProject_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23nQOAYNt_fe"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pvT5rwiuoCJ"
      },
      "source": [
        "Since I wanted to use image segmentation on a large RGB dataset, I needed to pick a model and architecture that will: \n",
        "1. be specific enough to consistently detect urban design patterns\n",
        "2. be generalized enough to not overfit on\n",
        "    * *street-like* shapes\n",
        "    * chaotic assortments of cars, trees, & such\n",
        "    * potentially unclassified or incorrect RoW  \n",
        "3. not be too process intensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DdbTWyJ2_1i"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "\n",
        "PROJ_DIR = 'drive/MyDrive/Penn/MUSA-650/FinalProject'\n",
        "\n",
        "%cd {PROJ_DIR}\n",
        "\n",
        "#DATA_DIR = PROJ_DIR + '/' + 'data'\n",
        "DATA_DIR = 'data'\n",
        "\n",
        "IMAGE_PATH = DATA_DIR + '/clean/' + 'sf_naip_images.parquet'\n",
        "MASK_PATH = DATA_DIR + '/clean/' + 'sf_naip_mask.parquet'\n",
        "INFO_PATH = DATA_DIR + '/clean/' + 'sf_naip_info.parquet'\n",
        "\n",
        "!python -m pip install 'fsspec>=0.3.3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1E7ee5fL-uu"
      },
      "outputs": [],
      "source": [
        "# CLEAN DATAFRAMES AND TURN THEM TO ARRAYS\n",
        "def df_to_array(arr_df):\n",
        "  # import csv of image data \n",
        "  ## pre-flattened\n",
        "  cols = [col for col in list(arr_df) if 'Unnamed' not in col]\n",
        "  arr_df = arr_df[cols]\n",
        "\n",
        "  # list of shape index colnames\n",
        "  icols = [col for col in list(arr_df) if 'ass' not in col]\n",
        "  # make array out of rgb dataframe\n",
        "  #image_arr = np.stack(arr_df[icols].apply(list, axis=1))\n",
        "  image_arr = arr_df[icols].to_numpy(dtype='int')\n",
        "  print('Shape: {}'.format(image_arr.shape))\n",
        "\n",
        "  return image_arr\n",
        "\n",
        "# UNFLATTEN FUNCTION\n",
        "def unflatten(array, new_shape):\n",
        "  # shape initial\n",
        "  n_samples = array.shape[0]\n",
        "  flat_shape = array.shape[1]\n",
        "\n",
        "  new_shape = [n_samples] + list(new_shape)\n",
        "\n",
        "  return array.reshape(new_shape)\n",
        "\n",
        "# SHAPES\n",
        "img_shape = (128, 128, 4)\n",
        "mask_shape = (128, 128, 1)\n",
        "rgb_shape = (128,128,3)\n",
        "\n",
        "# IMPORT IMAGE ARRAYS\n",
        "img_dd = dd.read_parquet(\n",
        "             IMAGE_PATH,\n",
        "             blocksize=1000000,\n",
        "             sample=655360,\n",
        "             dtype='int'\n",
        "             )\n",
        "img_arr = df_to_array(img_dd.compute(scheduler='processes'))\n",
        "\n",
        "# IMPORT ROW MASKS\n",
        "mask_arr = df_to_array(pd.read_parquet(MASK_PATH))\n",
        "\n",
        "# IMPORT ADDITIONAL INFO\n",
        "info_df = pd.read_parquet(INFO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nInjS-2Z5hrm"
      },
      "source": [
        "### Train / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HI2Tmgp5fVq",
        "outputId": "db0ddccc-0b60-4603-dd77-f2eec70bc2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X train: (4702, 128, 128, 3)\n",
            "Y train: (4702, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import keras\n",
        "\n",
        "# load vgg model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "# SPLIT GREY DATAFRAME INTO 50/50 \n",
        "## WITH STRATIFICATION ON THE CLASSES COL\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    img_arr, mask_arr, \n",
        "    test_size=0.75, random_state=420\n",
        "    )\n",
        "## Scale the data\n",
        "scalar = MinMaxScaler()\n",
        "scalar.fit(X_train)\n",
        "#X_train = scalar.transform(X_train)\n",
        "#X_test = scalar.transform(X_test)\n",
        "X_train = unflatten(X_train, img_shape)[:,:,:,:3]\n",
        "#X_train = preprocess_input(X_train)\n",
        "X_test = unflatten(X_test, img_shape)[:,:,:,:3]\n",
        "#X_test = preprocess_input(X_test)\n",
        "y_train = unflatten(y_train, mask_shape)\n",
        "y_test = unflatten(y_test, mask_shape)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "print('X train: {}'. format(X_train.shape))\n",
        "print('Y train: {}'. format(y_train.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCnsm8Jonjas"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03LlyUsgnmgd"
      },
      "source": [
        "### Import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ2AvxBSeQte"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load the model\n",
        "vgg16 = VGG16(\n",
        "    include_top = False,\n",
        "    input_shape = rgb_shape,\n",
        "    weights='imagenet'\n",
        ")\n",
        "vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm1a4kWzkKkY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import \\\n",
        "  Conv2D, Conv2DTranspose, MaxPooling2D, \\\n",
        "  Dense, Activation, Dropout, \\\n",
        "  Flatten, Input, Concatenate, \\\n",
        "  BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "def conv_block(inputs,num_filters):\n",
        "  x = Conv2D(num_filters,3,padding='same')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(num_filters,3,padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x) \n",
        "  return x\n",
        "\n",
        "def define_decoder(inputs,skip_layer,num_filters):\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  x = Conv2DTranspose(\n",
        "        num_filters,(2,2),\n",
        "        strides=(2,2),\n",
        "        padding='same',\n",
        "        kernel_initializer=init\n",
        "      )(inputs)  \n",
        "  g = Concatenate()([x,skip_layer])\n",
        "  g = conv_block(g, num_filters)\n",
        "  return g\n",
        "\n",
        "def vgg16_unet(input_shape):\n",
        "  inputs = Input(shape=input_shape)\n",
        "  vgg16 = VGG16(include_top=False,weights='imagenet',input_tensor=inputs)  \n",
        "  # We will extract encoder layers based on their output shape from vgg16 model  \n",
        "  s1 = vgg16.get_layer('block1_conv2').output  \n",
        "  s2 = vgg16.get_layer('block2_conv2').output  \n",
        "  s3 = vgg16.get_layer('block3_conv3').output  \n",
        "  s4 = vgg16.get_layer('block4_conv3').output    # bottleneck/bridege layer from vgg16\n",
        "  b1 = vgg16.get_layer('block5_conv3').output #32\n",
        "  \n",
        "  # Decoder Block\n",
        "  d1 = define_decoder(b1,s4,512)\n",
        "  d2 = define_decoder(d1,s3,256)\n",
        "  d3 = define_decoder(d2,s2,128)\n",
        "  d4 = define_decoder(d3,s1,64)  #output layer\n",
        "  outputs = Conv2D(1,1, padding='same', activation='sigmoid')(d4)\n",
        "  model = Model(inputs,outputs)\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axniRW6hnwH0"
      },
      "source": [
        "### Import Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC7vG9Jel7_c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.math import reduce_sum\n",
        "\n",
        "# Dice Loss \n",
        "## a measure of overlap between two samples\n",
        "## ranges from 0 to 1 \n",
        "## a Dice coefficient of 1 denotes perfect and complete overlap\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true,y_pred):\n",
        "  y_true = Flatten()(y_true)\n",
        "  y_pred = Flatten()(y_pred)\n",
        "  intersection = reduce_sum(y_true*y_pred)\n",
        "  return (2. * intersection + smooth) / (reduce_sum(y_true) + reduce_sum(y_pred))\n",
        "  \n",
        "def dice_loss(y_true,y_pred):\n",
        "  return 1.0 - dice_coef(y_true,y_pred)\n",
        "\n",
        "# Intersection-Over-Union \n",
        "## a common evaluation metric for semantic image segmentation\n",
        "## true_positive / (true_positive + false_positive + false_negative)\n",
        "def iou(y_true,y_pred):\n",
        "  def f(y_true,y_pred):\n",
        "    intersection = (y_true*y_pred).sum()\n",
        "    union = y_true.sum() + y_pred.sum() - intersection\n",
        "    x = (intersection + 1e-15) / (union + 1e-15)\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "  return tf.numpy_function(f,[y_true,y_pred],tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R0VHWQHn0ds"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8xAbBFllfzX",
        "outputId": "168eef7b-163f-410b-e290-0560c840cf64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "model = vgg16_unet(rgb_shape)\n",
        "model.compile(\n",
        "    loss=dice_loss,\n",
        "    optimizer=Adam(lr = .001),\n",
        "    metrics=[dice_coef, iou, Recall(), Precision()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk0MF-man3ce"
      },
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN69hjc3t9UC"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeaKYjD1nWC1",
        "outputId": "61d4efca-967d-40bd-cd0a-732e22b2346c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 4432s 30s/step - loss: 0.2445 - dice_coef: 0.7555 - iou: 0.6095 - recall: 0.7806 - precision: 0.7519 - val_loss: 0.2305 - val_dice_coef: 0.7695 - val_iou: 0.6267 - val_recall: 0.7769 - val_precision: 0.7932\n",
            "Epoch 2/25\n",
            "147/147 [==============================] - 4356s 30s/step - loss: 0.1956 - dice_coef: 0.8044 - iou: 0.6744 - recall: 0.8102 - precision: 0.8070 - val_loss: 0.2085 - val_dice_coef: 0.7915 - val_iou: 0.6565 - val_recall: 0.7171 - val_precision: 0.8895\n",
            "Epoch 3/25\n",
            "147/147 [==============================] - 4371s 30s/step - loss: 0.1679 - dice_coef: 0.8321 - iou: 0.7138 - recall: 0.8293 - precision: 0.8399 - val_loss: 0.2650 - val_dice_coef: 0.7350 - val_iou: 0.5825 - val_recall: 0.7972 - val_precision: 0.6862\n",
            "Epoch 4/25\n",
            "147/147 [==============================] - 4364s 30s/step - loss: 0.1549 - dice_coef: 0.8452 - iou: 0.7333 - recall: 0.8379 - precision: 0.8568 - val_loss: 0.1587 - val_dice_coef: 0.8413 - val_iou: 0.7273 - val_recall: 0.8707 - val_precision: 0.8171\n",
            "Epoch 5/25\n",
            "147/147 [==============================] - 4375s 30s/step - loss: 0.1415 - dice_coef: 0.8585 - iou: 0.7533 - recall: 0.8518 - precision: 0.8683 - val_loss: 0.1509 - val_dice_coef: 0.8491 - val_iou: 0.7390 - val_recall: 0.8249 - val_precision: 0.8779\n",
            "Epoch 6/25\n",
            "147/147 [==============================] - 4359s 30s/step - loss: 0.1326 - dice_coef: 0.8674 - iou: 0.7668 - recall: 0.8569 - precision: 0.8805 - val_loss: 0.1719 - val_dice_coef: 0.8281 - val_iou: 0.7085 - val_recall: 0.7606 - val_precision: 0.9123\n",
            "Epoch 7/25\n",
            "147/147 [==============================] - 4357s 30s/step - loss: 0.1257 - dice_coef: 0.8743 - iou: 0.7778 - recall: 0.8650 - precision: 0.8859 - val_loss: 0.1410 - val_dice_coef: 0.8590 - val_iou: 0.7542 - val_recall: 0.8116 - val_precision: 0.9149\n",
            "Epoch 8/25\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.1252 - dice_coef: 0.8747 - iou: 0.7787 - recall: 0.8652 - precision: 0.8887 "
          ]
        }
      ],
      "source": [
        "EPOCHS = 25\n",
        "#train_steps = len(X_train)//batch_size\n",
        "#test_steps = len(X_test)//batch_size\n",
        "\n",
        "history = model.fit(\n",
        "  X_train, tf.cast(y_train, tf.float32),\n",
        "  epochs=EPOCHS,\n",
        "  validation_data=(X_test, tf.cast(y_test, tf.float32))#,\n",
        "  #steps_per_epoch=train_steps,\n",
        "  #validation_steps=test_steps\n",
        "  )\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTvCMY2BtY2_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqH3CR16_ziY"
      },
      "outputs": [],
      "source": [
        "import datetime \n",
        "\n",
        "now = datetime.datetime.now()\n",
        "dt_string = now.strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "model_path = os.path.join(DATA_DIR, 'models', 'vgg16_model_{}.keras'.format(dt_string))\n",
        "model.save(model_path)\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "history_path = os.path.join(DATA_DIR, 'models', 'vgg16_history_{}.csv'.format(dt_string))\n",
        "with open(history_path, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtLTTYqwYK4e"
      },
      "outputs": [],
      "source": [
        "reconstructed_model.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIM55yKbaFG"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xus-GXJ_ScDZ"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBpdbgr-tlWx"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(fitted_model, num_epoch = EPOCHS):\n",
        "  import matplotlib.pyplot as plt\n",
        "  fig, ax = plt.subplots(1,2, figsize=[18,6])\n",
        "  ax[0].plot(range(1, num_epoch+1), fitted_model.history['loss'], c='blue', label='Training loss')\n",
        "  ax[0].plot(range(1, num_epoch+1), fitted_model.history['val_loss'], c='red', label='Validation loss')\n",
        "  ax[0].legend()\n",
        "  ax[0].set_xlabel('epochs')\n",
        "\n",
        "  ax[1].plot(range(1, num_epoch+1), fitted_model.history['accuracy'], c='blue', label='Training accuracy')\n",
        "  ax[1].plot(range(1, num_epoch+1), fitted_model.history['val_accuracy'], c='red', label='Validation accuracy')\n",
        "  ax[1].legend()\n",
        "  ax[1].set_xlabel('epochs')\n",
        "\n",
        "plot_loss_acc(model, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X9n7dlD8EuU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from skimage.io import imread\n",
        "import matplotlib\n",
        "from matplotlib import colors\n",
        "\n",
        "# counts array equal to focus value\n",
        "def count_focus(array, value=1):\n",
        "    return len(array[array==value])\n",
        "# get percent that the array is equal to value\n",
        "## used for filter masks\n",
        "def get_pct_arr(focus_array, value=1):\n",
        "    return np.array([count_focus(arr, value=value)/arr.size for arr in focus_array])\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef_arr(y_true,y_pred):\n",
        "  y_true = np.array(y_true).flatten()\n",
        "  y_pred = np.array(y_pred).flatten()\n",
        "  intersection = reduce_sum(y_true*y_pred)\n",
        "  return (2. * intersection + smooth) / (reduce_sum(y_true) + reduce_sum(y_pred))\n",
        "  \n",
        "def dice_loss_arr(y_true,y_pred):\n",
        "  return 1.0 - dice_coef(y_true,y_pred)\n",
        "\n",
        "def arr_to_binary(arr, cutoff=1.0, buffer=.01, good=1, bad=0):\n",
        "  arr[arr>=cutoff-buffer] = good\n",
        "  arr[arr<cutoff-buffer] = bad\n",
        "  return arr\n",
        "\n",
        "def get_masked_cmap(arr, thresh = 1.0, cmap='red'):\n",
        "  masked_array = np.ma.masked_where(arr < thresh, arr)\n",
        "  cmap = colors.ListedColormap([cmap])\n",
        "  return masked_array, cmap\n",
        "\n",
        "cols, rows = 4, 5\n",
        "axes = []\n",
        "[[axes.append((c,r)) for r in range(rows)] for c  in range(cols)]\n",
        "axis_count = len(axes)\n",
        "fig, ax = plt.subplots(rows, cols, figsize=[12, 16])\n",
        "\n",
        "for row, idx in enumerate(random.sample(range(len(X_test)), rows)):\n",
        "\n",
        "    focus_image, observed_mask = X_test[idx:idx+1,:,:,:], y_test[idx:idx+1,:,:,:]\n",
        "    \n",
        "    predicted_mask = model.predict(tf.cast(focus_image, tf.float32))\n",
        "\n",
        "    predicted_mask_thresh = arr_to_binary(predicted_mask.copy(), buffer=0.01)\n",
        "    dice_loss = dice_loss_arr(tf.cast(observed_mask, tf.float32), predicted_mask_thresh)\n",
        "    \n",
        "    pct_observed = get_pct_arr(observed_mask)[0]\n",
        "    pct_predicted = get_pct_arr(predicted_mask)[0]\n",
        "    pct_predicted_thresh = get_pct_arr(predicted_mask_thresh)[0]\n",
        "\n",
        "    ax[row, 0].imshow(focus_image[0])\n",
        "    ax[row, 0].set_title('RGB Image' + '\\n' + 'Dice Loss: {:.2f}'.format(dice_loss))\n",
        "\n",
        "    ax[row, 1].imshow(focus_image[0])\n",
        "    ax[row, 1].imshow(observed_mask.reshape(128,128), alpha=.5)\n",
        "    ax[row, 1].set_title('Right-of-Way Mask' + '\\n' + 'Observed Pct: {0:.0%}'.format(pct_observed))\n",
        "    \n",
        "\n",
        "    \n",
        "    ax[row, 2].imshow(focus_image[0])\n",
        "    ax[row, 2].imshow(predicted_mask.reshape(128,128), alpha=.5)\n",
        "\n",
        "    diff_mask = arr_to_binary(predicted_mask - observed_mask, buffer=0.01, bad=np.nan).reshape(128,128)\n",
        "    diff_mask, cmap = get_masked_cmap(diff_mask, cmap='green')\n",
        "    ax[row, 2].imshow(diff_mask, cmap=cmap)\n",
        "    diff_mask  = arr_to_binary(observed_mask - predicted_mask, buffer=0.01, bad=np.nan).reshape(128,128)\n",
        "    diff_mask, cmap = get_masked_cmap(diff_mask, cmap='red')\n",
        "    ax[row, 2].imshow(diff_mask, cmap=cmap)\n",
        "    #ax[row, 2].set_title('Pct Roads: {0:.1%}'.format(pct_roads) + '\\n' + 'Pct Diff: {0:.1%}'.format(pct_diff))\n",
        "    ax[row, 2].set_title('Predicted Mask' + '\\n' + 'Predicted Pct: {0:.0%}'.format(pct_predicted))\n",
        "    \n",
        "    \n",
        "\n",
        "    ax[row, 3].imshow(focus_image[0])\n",
        "    ax[row, 3].imshow(predicted_mask_thresh.reshape(128,128), alpha=.5)\n",
        "\n",
        "    diff_mask = arr_to_binary(predicted_mask_thresh - observed_mask, buffer=0.01, bad=np.nan).reshape(128,128)\n",
        "    diff_mask, cmap = get_masked_cmap(diff_mask, cmap='green')\n",
        "    ax[row, 3].imshow(diff_mask, cmap=cmap)\n",
        "    diff_mask  = arr_to_binary(observed_mask - predicted_mask_thresh, buffer=0.01, bad=np.nan).reshape(128,128)\n",
        "    diff_mask, cmap = get_masked_cmap(diff_mask, cmap='red')\n",
        "    ax[row, 3].imshow(diff_mask, cmap=cmap)\n",
        "    #ax[row, 3].imshow(predicted_mask_thresh.reshape(128,128), alpha=.5)\n",
        "    ax[row, 3].set_title('Predicted Mask (p>1)' + '\\n' + 'Predict Thresh Pct: {0:.0%}'.format(pct_predicted_thresh))\n",
        "\n",
        "    for col in range(cols):\n",
        "        ax[row, col].set_axis_off()\n",
        "fig.patch.set_facecolor('#FFFFFF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiPZnO-6xpdd"
      },
      "outputs": [],
      "source": [
        "arr = arr_to_binary(observed_mask - predicted_mask_thresh, buffer=0, bad=0).reshape(128,128)\n",
        "thresh=1\n",
        "np.ma.masked_where(arr < thresh, arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3VuCV6pqf_l"
      },
      "outputs": [],
      "source": [
        "diff_mask[~np.isnan(diff_mask)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgHJwIkOYt__"
      },
      "outputs": [],
      "source": [
        "smooth = 1e-15\n",
        "def dice_coef(y_true,y_pred):\n",
        "  y_true = np.array(y_true).flatten()\n",
        "  y_pred = np.array(y_pred).flatten()\n",
        "  intersection = reduce_sum(y_true*y_pred)\n",
        "  return (2. * intersection + smooth) / (reduce_sum(y_true) + reduce_sum(y_pred))\n",
        "  \n",
        "def dice_loss(y_true,y_pred):\n",
        "  return 1.0 - dice_coef(y_true,y_pred)\n",
        "\n",
        "dice_loss(tf.cast(focus_image, tf.float32), predicted_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcqUVaXocVOB"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FinalProject_model",
      "provenance": [],
      "authorship_tag": "ABX9TyP8jeVBLFSkULIUDll9IkSJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}